name: Deploy to Compute Engine

on:
  push:
    branches: testing-deployment-automation
  workflow_dispatch:
    inputs:
      deployment_target:
        description: 'Where to deploy Airflow'
        required: true
        default: 'compute_engine'
        type: choice 
        options:
          - local
          - compute_engine

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r Data_Pipeline/requirementstest.txt
      - name: Set PYTHONPATH
        run: |
          echo "PYTHONPATH=$(pwd)/Data_Pipeline:$(pwd)" >> $GITHUB_ENV
          echo "PYTHONPATH set to $(pwd)/Data_Pipeline:$(pwd)"
      - name: Run Unit Tests
        run: |
          python -m unittest discover -s Data_Pipeline/tests -p "test*.py"
      - name: Authenticate with Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      
      - name: Update gcloud components
        run: |
          gcloud components update --quiet


      - name: Ensure Artifact Registry
        run: |
          chmod +x scripts/create_or_ensure_artifact_registry.sh
          ./scripts/create_or_ensure_artifact_registry.sh


      # ---------- CONDITIONAL DOCKER BUILD ----------
      - name: Check if Docker Build is Needed
        id: detect-changes
        run: |
          PROJECT_ID="primordial-veld-450618-n4"
          REPO_NAME="airflow-docker-image"
          IMAGE_NAME="data-pipeline"
          IMAGE_TAG="latest"
          REPO_URI="us-central1-docker.pkg.dev/${PROJECT_ID}/${REPO_NAME}"

          echo "üîç Checking if remote image exists in Artifact Registry..."

          EXISTING_IMAGE=$(gcloud artifacts docker images list ${REPO_URI} \
            --format="value(DISPLAY_NAME)" \
            --filter="DISPLAY_NAME:(${IMAGE_NAME}:${IMAGE_TAG})")

          if [[ -z "$EXISTING_IMAGE" ]]; then
            echo "‚ö†Ô∏è Remote image not found in Artifact Registry."
            echo "build_required=true" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ Remote image found: $EXISTING_IMAGE"
            echo "üîç Checking if Dockerfile or requirements changed via git diff..."

            if git diff --quiet HEAD~1 HEAD -- \
              Data_Pipeline/Dockerfile \
              Data_Pipeline/requirements.txt; then
              echo "build_required=false" >> $GITHUB_OUTPUT
            else
              echo "build_required=true" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Configure Docker for Artifact Registry
        run: |
          gcloud auth configure-docker us-central1-docker.pkg.dev --quiet

      # - name: Build & Push data-pipeline Image
      #   if: steps.detect-changes.outputs.build_required == 'true'
      #   run: |
      #     echo "üöÄ Docker build triggered (image missing or code changed)."
      #     PROJECT_ID="primordial-veld-450618-n4"
      #     REPO_NAME="airflow-docker-image"
      #     IMAGE_NAME="data-pipeline"
      #     IMAGE_TAG="latest"

      #     # Build
      #     docker build -t us-central1-docker.pkg.dev/$PROJECT_ID/$REPO_NAME/$IMAGE_NAME:$IMAGE_TAG Data_Pipeline

      #     # Push
      #     docker push us-central1-docker.pkg.dev/$PROJECT_ID/$REPO_NAME/$IMAGE_NAME:$IMAGE_TAG

      - name: Test Docker Push
        run: |
          # Set variables
          PROJECT_ID="primordial-veld-450618-n4"
          REPO_NAME="airflow-docker-image"
          IMAGE_NAME="test-push-image"
          IMAGE_TAG="latest"
          REPO_URI="us-central1-docker.pkg.dev/${PROJECT_ID}/${REPO_NAME}"
          
          echo "Testing docker push to ${REPO_URI}/${IMAGE_NAME}:${IMAGE_TAG}"
          
          # Create a minimal Dockerfile for testing
          echo -e "FROM alpine\nCMD [\"echo\", \"Test push successful!\"]" > Dockerfile.test
          
          # Build the test image
          docker build -t ${REPO_URI}/${IMAGE_NAME}:${IMAGE_TAG} -f Dockerfile.test .
          
          # Push the test image to Artifact Registry
          docker push ${REPO_URI}/${IMAGE_NAME}:${IMAGE_TAG}
          
          echo "Test Docker push completed successfully."


      - name: Ensure Airflow Server VM & Firewall
        if: ${{ github.event_name == 'push' || inputs.deployment_target == 'compute_engine' || inputs.deployment_target == 'both' }}
        run: |
          chmod +x scripts/create_or_start_airflow_server_vm.sh
          ./scripts/create_or_start_airflow_server_vm.sh


      - name: Determine Compute Engine User
        run: |
          COMPUTE_ENGINE_USER=$(gcloud config get-value account 2>/dev/null || echo "ubuntu")
          echo "COMPUTE_ENGINE_USER=${COMPUTE_ENGINE_USER}" >> $GITHUB_ENV
          echo "‚úÖ COMPUTE_ENGINE_USER set to ${COMPUTE_ENGINE_USER}"


      # ---------- SSH KEYS -----------
      - name: Configure SSH to VM
        run: |
          echo "üöÄ Ensuring SSH key for GitHub Actions..."
          if [ ! -f ~/.ssh/github-actions-key ]; then
            ssh-keygen -t rsa -b 4096 -C "github-actions" -N "" -f ~/.ssh/github-actions-key
            echo "‚úÖ SSH Key generated!"
          else
            echo "‚úÖ SSH Key already exists!"
          fi

          PUBLIC_KEY=$(cat ~/.ssh/github-actions-key.pub)
          VM_NAME="airflow-server-vm"
          VM_ZONE="us-central1-a"

          # Attach public key to VM metadata if missing
          EXISTING_KEYS=$(gcloud compute instances describe $VM_NAME --zone $VM_ZONE --format="value(metadata.ssh-keys)" || echo "")
          if [[ "$EXISTING_KEYS" != *"$PUBLIC_KEY"* ]]; then
            echo "üîë Adding SSH key to VM metadata..."
            gcloud compute instances add-metadata $VM_NAME --zone $VM_ZONE \
              --metadata=ssh-keys="${{ secrets.COMPUTE_ENGINE_USER }}:$PUBLIC_KEY"
            echo "‚úÖ SSH key added to VM!"
          else
            echo "‚úÖ SSH key is already in VM metadata!"
          fi


    # ---------- SYNC FILES -----------
      - name: Sync Airflow Project Files to VM
        run: |
          VM_NAME="airflow-server-vm"
          VM_ZONE="us-central1-a"
          echo "üöÄ Syncing project files to $VM_NAME..."

          ssh -o StrictHostKeyChecking=no -i ~/.ssh/github-actions-key ${{ secrets.COMPUTE_ENGINE_USER }}@${{ secrets.COMPUTE_ENGINE_IP }} << 'EOF'
            sudo mkdir -p /opt/airflow
            sudo chown -R $USER:$USER /opt/airflow
            sudo chmod -R 775 /opt/airflow
          EOF

          rsync -avz \
            -e "ssh -o StrictHostKeyChecking=no -i ~/.ssh/github-actions-key" \
            --exclude '.git' \
            . ${{ secrets.COMPUTE_ENGINE_USER }}@${{ secrets.COMPUTE_ENGINE_IP }}:/opt/airflow

          echo "‚úÖ Files synced successfully."
      

      - name: Deploy Airflow on Compute Engine
        run: |
          ssh -o StrictHostKeyChecking=no -i ~/.ssh/github-actions-key ${{ secrets.COMPUTE_ENGINE_USER }}@${{ secrets.COMPUTE_ENGINE_IP }} << 'EOF'
            echo "üöÄ Ensuring Docker is installed..."
            if ! command -v docker &> /dev/null; then
              echo "‚ùå Docker is not installed. Installing..."
              sudo apt-get update -y
              echo "üöÄ Adding Docker repository..."
              sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common
              curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
              sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
              sudo apt-get update -y
              sudo apt-get install -y docker-ce docker-ce-cli containerd.io
            else
              echo "‚úÖ Docker is already installed."
            fi

            if ! command -v docker-compose &> /dev/null; then
              echo "‚ùå Docker Compose not found. Installing latest version..."
              DOCKER_COMPOSE_VERSION=$(curl -s https://api.github.com/repos/docker/compose/releases/latest | grep -Po '"tag_name": "\K.*?(?=")')
              sudo curl -L "https://github.com/docker/compose/releases/download/${DOCKER_COMPOSE_VERSION}/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
              sudo chmod +x /usr/local/bin/docker-compose
              sudo ln -sf /usr/local/bin/docker-compose /usr/bin/docker-compose
            else
              echo "‚úÖ Docker Compose is already installed."
            fi

            # Give user Docker permissions
            echo "üîÑ Adding user to Docker group..."
            sudo usermod -aG docker $USER
            newgrp docker
            sudo systemctl restart docker
            echo "‚úÖ User added to Docker group and Docker restarted."

            # Fix Docker socket perms
            sudo chmod 666 /var/run/docker.sock
            echo "‚úÖ Docker socket permissions fixed."

            mkdir -p /opt/airflow
            echo "airflow dir created."
            echo "üöÄ Ensuring GCP Key File exists..."
            if [ -d /opt/airflow/gcp-key.json ]; then
                echo "‚ö†Ô∏è Found directory at /opt/airflow/gcp-key.json. Removing it..."
                sudo rm -rf /opt/airflow/gcp-key.json
            fi
            echo "üöÄ Creating GCP Key File..."
            echo '${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}' | jq . > /opt/airflow/gcp-key.json
            chmod 644 /opt/airflow/gcp-key.json
            sudo chown ubuntu:docker /opt/airflow/gcp-key.json
            echo "‚úÖ GCP Key File Created."

            echo "üöÄ Fixing Airflow log directory permissions..."
            sudo mkdir -p /opt/airflow/logs
            sudo chmod -R 777 /opt/airflow/logs
            sudo chown -R $USER:$USER /opt/airflow/logs
            
            # ‚úÖ Ensure the user can access Docker without root privileges
            echo "‚úÖ Log directory permissions fixed."
            echo "‚úÖ Airflow successfully started!"

          EOF
      - name: Get Airflow Webserver IP
        run: |
          EXTERNAL_IP=$(gcloud compute instances describe airflow-server --zone us-central1-a --format="get(networkInterfaces[0].accessConfigs[0].natIP)")
          echo "üåç Airflow UI is available at: http://$EXTERNAL_IP:8080"
      
      # ‚úÖ Remove SSH Key after deployment (Security)
      - name: Remove SSH Key
        run: rm -f ~/.ssh/github-actions-key ~/.ssh/github-actions-key.pub