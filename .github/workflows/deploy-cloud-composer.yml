name: Deploy Airflow DAGs to Cloud Composer

on:
  push:
    branches:
      - testing-pipeline
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Authenticate with Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

      - name: Set Up gcloud CLI
        uses: google-github-actions/setup-gcloud@v1

      - name: Enable Required APIs
        run: |
          gcloud services enable \
            composer.googleapis.com \
            cloudresourcemanager.googleapis.com \
            storage.googleapis.com

      - name: Get Cloud Composer DAGs Bucket
        id: get-bucket
        run: |
          REGION="us-central1"
          BUCKET_NAME=$(gcloud composer environments describe my-airflow-env --location $REGION --format="value(config.dagGcsPrefix)")
          echo "BUCKET_NAME=$BUCKET_NAME" >> $GITHUB_ENV

      - name: Upload DAGs to Cloud Storage
        run: |
          gsutil -m cp -r dags/*.py $BUCKET_NAME/dags/

      - name: Restart Airflow Scheduler & Webserver
        run: |
          gcloud composer environments run my-airflow-env --location us-central1 restart-webserver
          gcloud composer environments run my-airflow-env --location us-central1 restart-scheduler

      - name: List DAGs in Airflow
        run: |
          gcloud composer environments run my-airflow-env --location us-central1 dags list
