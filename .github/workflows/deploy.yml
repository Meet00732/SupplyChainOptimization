name: Deploy Supply Chain Optimization

on:
  push:
    branches: testing-pipeline
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install docker-compose
      
      - name: Create secret directory
        run: mkdir -p secret
      
      - name: Set up GCP credentials
        run: |
          echo '${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}' > secret/gcp-key.json
          chmod 600 secret/gcp-key.json
          # Verify the file exists and has content
          ls -la secret/
          if [ -s secret/gcp-key.json ]; then
            echo "✅ GCP Key has content"
            # Verify it's valid JSON
            if jq . secret/gcp-key.json > /dev/null 2>&1; then
              echo "✅ GCP Key appears to be valid JSON"
            else
              echo "❌ GCP Key is not valid JSON"
              exit 1
            fi
          else
            echo "❌ GCP Key is empty"
            exit 1
          fi
      
      - name: Create .env file
        run: |
          cat > .env << 'EOL'
          # PostgreSQL Configuration
          POSTGRES_USER=airflow
          POSTGRES_PASSWORD=airflow
          POSTGRES_DB=airflow

          # Airflow Configuration
          AIRFLOW_DATABASE_PASSWORD=airflow
          AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
          REDIS_PASSWORD=redispass

          # Airflow Admin User
          AIRFLOW_ADMIN_USERNAME=admin
          AIRFLOW_ADMIN_PASSWORD=admin
          AIRFLOW_ADMIN_FIRSTNAME=Admin
          AIRFLOW_ADMIN_LASTNAME=User
          AIRFLOW_ADMIN_EMAIL=admin@example.com

          # Airflow UID
          AIRFLOW_UID=50000

          # Docker Group ID
          DOCKER_GID=0

          # Airflow Image
          AIRFLOW_IMAGE_NAME=apache/airflow:2.7.3-python3.10
          
          # GCP Configuration
          GOOGLE_APPLICATION_CREDENTIALS=/app/secret/gcp-key.json
          EOL
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Create necessary directories
        run: |
          mkdir -p logs
          mkdir -p dags
          mkdir -p plugins
          chmod -R 777 logs dags plugins
      
      - name: List files to verify docker-compose.yaml exists
        run: |
          ls -la
          echo "Checking if docker-compose.yaml exists"
          if [ -f "docker-compose.yaml" ]; then
            echo "✅ docker-compose.yaml exists"
          else
            echo "❌ docker-compose.yaml does not exist"
            exit 1
          fi
      
      - name: Modify airflow-init command
        run: |
          # Create a temporary file with the modified docker-compose
          sed '/airflow-init:/,/depends_on:/s/command: >/command: >-/' docker-compose.yaml > docker-compose.temp.yaml
          # Replace the original file
          mv docker-compose.temp.yaml docker-compose.yaml
      
      - name: Deploy with Docker Compose
        run: |
          docker-compose up -d postgres redis
          # Wait for postgres and redis to be healthy
          echo "Waiting for postgres and redis to be healthy..."
          sleep 30
          
          # Run airflow-init separately with more detailed output
          docker-compose up --no-start airflow-init
          docker-compose start airflow-init
          docker-compose logs airflow-init
          
          # Check if airflow-init completed successfully
          INIT_EXIT_CODE=$(docker-compose ps -q airflow-init | xargs docker inspect -f '{{.State.ExitCode}}')
          if [ "$INIT_EXIT_CODE" != "0" ]; then
            echo "airflow-init failed with exit code $INIT_EXIT_CODE"
            exit 1
          fi
          
          # Start the remaining services
          docker-compose up -d airflow-webserver airflow-scheduler airflow-worker flower data-pipeline
      
      - name: Check service status
        run: |
          docker-compose ps
          docker-compose logs